## Chapter 4: Implementation

Self-Evaluation Tool is a web-based application designed to facilitate student self-assessment and provide management capabilities for educators. The discussion herein encompasses the overall software architecture, a detailed breakdown of the functionalities implemented in both the backend Application Programming Interface (API) and the frontend User Interface (UI), justifications for pivotal design and technology choices, an overview of the development process, and an exploration of potential avenues for future enhancements.

### 4.1 Software Architecture

The Self-Evaluation Tool is architected as a modern, decoupled, two-tier client-server system, promoting modularity, scalability, and maintainability. The core components are:

1.  **Backend API:** A RESTful API developed using the **FastAPI** framework in Python. FastAPI was selected due to its high performance (built on Starlette and Pydantic), asynchronous capabilities ideal for I/O-bound operations, automatic data validation and serialization provided by Pydantic, and built-in support for generating interactive API documentation (Swagger UI and ReDoc via OpenAPI). The backend encapsulates all business logic, data persistence, user authentication and authorization, and the complex survey scoring and feedback generation mechanisms.

2.  **Frontend User Interface (UI):** A Single Page Application (SPA) constructed with **React** and **TypeScript**. React's component-based paradigm facilitates the creation of a modular and reusable UI. TypeScript introduces static typing, enhancing code quality, maintainability, and developer productivity, especially in larger projects. **Vite** serves as the build tool and development server, offering rapid Hot Module Replacement (HMR) and optimized production builds.

3.  **Database:** **MongoDB**, a NoSQL document-oriented database, was chosen for data storage. Its schema flexibility is advantageous for handling diverse and potentially evolving data structures inherent in survey tools, such as varied question types and feedback rules. The backend interacts with MongoDB asynchronously using the `motor` driver.

4.  **Containerization and Orchestration:** **Docker** is employed to containerize the backend API and the Nginx-served frontend application. **Docker Compose** defines and manages the multi-container application environments for development, testing, and production, ensuring environmental consistency and simplifying deployment workflows.

5.  **Web Server (Production):** In the production environment, **Nginx** is utilized to serve the static frontend assets (generated by Vite's build process) and to act as a reverse proxy, directing API-bound requests to the FastAPI backend. This is a standard and robust deployment pattern for SPAs.

**Figure 4.1: High-Level System Architecture**
*(A diagram would be inserted here, illustrating the client browser, Nginx (as reverse proxy and static server), the React UI, the FastAPI backend, and the MongoDB database, with arrows indicating primary request/response flows and data interactions.)*

**Communication Protocol:**
User interactions initiate in the client's web browser with the React UI. The UI, in turn, communicates with the backend via asynchronous HTTP requests (GET, POST, PUT, DELETE) to clearly defined API endpoints, prefixed with `/api/v1`. The FastAPI backend processes these requests, performs necessary business logic and database operations, and returns responses in JSON format. Pydantic models on the backend ensure data validation for requests and serialization for responses, forming a strong contract with the frontend, where corresponding TypeScript types are used.

### 4.2 Backend Implementation (FastAPI)

The backend is organized into distinct modules, each corresponding to a core domain entity, thereby adhering to the principle of separation of concerns.

**4.2.1 Core Infrastructure:**
*   **Application Entry Point (`main.py`):** Initializes the FastAPI application, configures essential middleware (CORS for cross-origin requests, SessionMiddleware for user sessions), and registers modular API routers. It also manages a lifespan event handler for establishing and closing the MongoDB connection.
*   **Database Interaction (`core/db.py`):** Centralizes MongoDB connection management using an asynchronous client (`motor`). It provides utility functions for accessing specific database collections and ensures that the database connection is available throughout the application's lifecycle.
*   **Configuration (`core/settings.py`):** Consolidates all application settings, loaded primarily from environment variables. This includes database URIs, secret keys for session management, allowed CORS origins, and application-specific constants like `STANDARD_QUESTION_MAX_SCORE`.
*   **Data Modeling (Pydantic):** Pydantic models are pervasively used to define the structure and validation rules for API request bodies and response payloads. Custom types, such as `PyObjectId`, bridge BSON ObjectIds with Python typing.

**4.2.2 Functional Modules:**

*   **User Management (`users/`):**
    *   **Authentication & Authorization:** Implements user registration (signup) with bcrypt-based password hashing (`passlib`) and login functionality. User sessions are managed server-side via `starlette.middleware.sessions.SessionMiddleware`. A `require_teacher_role` dependency restricts access to teacher-specific operations.
    *   **Endpoints:** `/signup`, `/login`, `/logout`, `/me` (to fetch current user details).
*   **Course Management (`courses/`):**
    *   **Functionality:** Provides full CRUD (Create, Read, Update, Delete) operations for academic courses or skills. Course creation, updates, and deletions are restricted to users with a 'teacher' role.
    *   **Integrity:** Prevents deletion of courses actively used in surveys. Deleting a course cascades to remove associated `QuestionCourseAssociation` (QCA) records.
*   **Question Management (`questions/`):**
    *   **Functionality:** Enables teachers to perform CRUD operations on assessment questions.
    *   **Question Types:** Supports diverse question formats (`AnswerTypeEnum`: `multiple_choice`, `multiple_select`, `input`, `range`), each with specific `answer_options` (e.g., choices, min/max values) and `scoring_rules` (e.g., correct keys, expected text, target values).
    *   **Validation:** Employs Pydantic model validators (`check_options_and_rules_consistency`) to ensure logical consistency between a question's type, its options, and its scoring rules at the point of creation or update.
    *   **Integrity:** Deleting a question also removes its associations with courses (QCAs).
*   **Question-Course Associations (`qca/`):**
    *   **Functionality:** Manages the link between questions and courses, allowing a question to be used in the context of multiple courses and a course to comprise multiple questions. Teachers manage these associations.
    *   **Contextualization:** Each QCA can define an `answer_association_type` (`positive` or `negative` contribution to course score) and `feedbacks_based_on_score` specific to the question-course pair, overriding default question feedback.
*   **Survey Management (`surveys/`):**
    *   **Functionality:** Allows teachers to create, read, update, and delete surveys. Updates include modifying title, description, associated courses, publish status, and course-level feedback/outcome thresholds.
    *   **Dynamic Score Calculation:** Upon survey creation or update, the backend calculates and stores `max_scores_per_course` (sum of `STANDARD_QUESTION_MAX_SCORE` for unique questions associated with each course via QCAs) and `max_overall_survey_score` (sum of `STANDARD_QUESTION_MAX_SCORE` for all unique questions across all associated courses in the survey).
    *   **Publishing:** Surveys can be marked as "published" to be visible and available to students.
    *   **Integrity:** Prevents deletion of surveys that have already been submitted by students. Deletion of a survey cascades to remove its associated (unsubmitted) `SurveyAttempt` and `StudentAnswer` records.
*   **Survey Attempt & Scoring Logic (`survey_attempts/`):**
    *   **Attempt Lifecycle:**
        *   `POST /start`: Initiates or resumes an unsubmitted survey attempt for a student. Max score information from the parent survey is copied to the attempt document.
        *   `POST /{attempt_id}/answers`: Allows students to save their answers for questions within an attempt. This can be called multiple times.
        *   `POST /{attempt_id}/submit`: Finalizes the survey attempt. This triggers:
            1.  Calculation of `score_achieved` for each `StudentAnswer` using the `calculate_score_for_answer` utility, which handles different question types and normalizes scores (capped at `STANDARD_QUESTION_MAX_SCORE`).
            2.  Aggregation of question scores into `course_scores` for each associated course, respecting the `answer_association_type` (positive/negative).
            3.  Calculation of `actual_overall_survey_score` by summing the `score_achieved` for each unique `question_id` across all answers in the attempt.
            4.  Generation of `course_feedback`, `detailed_feedback` (per course), `overall_survey_feedback`, and `course_outcome_categorization` using the `generate_all_feedback_and_outcomes_for_attempt` utility, which evaluates predefined thresholds against calculated scores.
    *   **Results Retrieval:** Endpoints for students to get their own results (`GET /{attempt_id}/results`) and for teachers to retrieve results for attempts on their surveys.
    *   **Listing Attempts:** `GET /my` for students; `GET /by-survey/{survey_id}` for teachers.

### 4.3 Frontend Implementation (React & TypeScript)

The frontend provides a responsive and interactive user interface, built with React and TypeScript, ensuring a type-safe and maintainable codebase.

**4.3.1 Core Structure and Technologies:**
*   **Vite:** Serves as the build tool and development server, enabling fast refresh and optimized production builds.
*   **React Router (`react-router-dom`):** Manages client-side navigation, defining routes for different pages and views within the SPA.
*   **TailwindCSS:** A utility-first CSS framework used for styling, providing rapid UI development and consistency.
*   **Component-Based Design:** The UI is architected with reusable React components (`src/components/`) for forms, modals, tables, question inputs, and result displays, promoting modularity.
*   **Page Structure:** Each distinct view is represented by a page component in `src/pages/`.
*   **API Services (`src/services/`):** Axios-based services encapsulate all HTTP communication with the backend API, with `apiClient.ts` handling base URL configuration and a global interceptor for 401 errors.
*   **TypeScript Types (`src/types/`):** Interfaces and enums define the shape of data exchanged with the backend, mirroring Pydantic models for strong typing across the application stack.

**4.3.2 State Management and Contexts:**
*   **`AuthContext`:** Manages global user authentication state, including the current user object, loading status, and `isAuthenticated` flag. It provides methods for login, signup, and logout, and fetches user data on initial application load to persist sessions.
*   **`NotificationContext`:** Offers a system for displaying global toast-like notifications for user feedback (e.g., success or error messages from API operations).
*   Local component state (React hooks: `useState`, `useEffect`, `useCallback`) is used for managing UI-specific state, form data, and data fetched from the API within individual components and pages.

**4.3.3 Key User Interface Functionalities:**

*   **Authentication:** `LoginPage` and `SignupPage` provide forms for user entry. `ProtectedRoute` ensures that routes are accessible based on authentication status and, optionally, user roles.
*   **Student Interface:**
    *   `HomePage`: Provides a personalized welcome and role-specific navigation.
    *   `SurveyListPage`: Displays available (published) surveys using `SurveyCard` components.
    *   `TakeSurveyPage`: Enables students to navigate through survey questions (presented one at a time, randomized from the backend), input answers using appropriate input components (`MultipleChoiceInput`, `TextInput`, etc., managed by `QuestionDisplay`), and submit the survey. The "Previous" button functionality has been corrected.
    *   `MyAttemptsPage`: Lists the student's survey attempts, displaying survey titles/descriptions, submission status, and overall scores.
    *   `SurveyResultsPage`: Presents a detailed breakdown of a submitted attempt, including the corrected `actual_overall_survey_score` (based on unique questions), per-course scores with percentages and max scores, textual feedback, and outcome categorizations per course (using `CourseResultCard`). Tooltips clarify scoring and outcome meanings.
*   **Teacher Interface:**
    *   `TeacherDashboardPage`: Acts as a central hub for teacher-specific management tasks.
    *   `CoursesPage`: Uses `ResourceTable` to list courses. Course creation and editing are handled via `CourseForm` within a `Modal`. A "Details" action navigates to `CourseDetailsPage`.
    *   `CourseDetailsPage`: Displays comprehensive information for a selected course, including a `ResourceTable` of associated questions. Provides a button to navigate to the `QuestionsPage` with the current course ID pre-filled for new question association.
    *   `QuestionsPage`: Manages questions using `ResourceTable`. The `QuestionForm` (modal) supports creating/editing questions with all their complex attributes (answer options, scoring rules, default feedback) and managing multiple QCAs, including course-specific feedback and association types. Handles URL query parameters (`edit`, `prefillCourseId`) to streamline workflows from other pages. Tooltips clarify complex configuration options.
    *   `SurveyManagementPage`: Teachers manage their surveys via `ResourceTable`. The `SurveyForm` (modal) facilitates survey creation/editing, including course association and defining course-specific feedback/outcome thresholds. Functionality includes publishing/unpublishing, copying survey links, and navigating to an overview of student attempts for a survey. Tooltips clarify various settings.
    *   `SurveyAttemptsOverviewPage`: Lists all student attempts for a particular survey created by the teacher.

### 4.4 Database Design (MongoDB)

MongoDB was selected as the database for its flexibility in handling diverse and potentially evolving data structures, characteristic of survey and assessment tools. The schema design is implicitly defined by the Pydantic models in the backend (`api/app/*/data_types.py`), which are then mapped to MongoDB documents. Key collections include: `users`, `courses`, `questions`, `question_course_associations`, `surveys`, `survey_attempts`, and `student_answers`. Relationships are primarily managed through `PyObjectId` references (e.g., a `survey` document contains an array of `course_ids`).

### 4.5 Deployment Strategy

The application is designed for containerized deployment using Docker and Docker Compose.
*   **Development (`docker-compose.dev.yml`):** Facilitates a local development environment with hot-reloading for both the FastAPI backend (using Uvicorn's reload feature) and the React frontend (via Vite's dev server). An Nginx development proxy (`nginx_dev`) is included to handle API proxying and Vite HMR WebSocket connections, mimicking a production-like setup.
*   **Testing (`docker-compose.test.yml`):** Defines an environment for running backend Pytest tests against a dedicated test MongoDB instance.
*   **Production (`docker-compose.yml`):** Configures the application for production deployment. The React UI is built into static assets and served by an Nginx container (`nginx_prod_proxy`). This Nginx instance also acts as a reverse proxy, forwarding API requests (`/api/*`, `/docs/*`, `/openapi.json`) to the FastAPI backend container, which runs Uvicorn without reload. Persistent data is managed using Docker volumes for the MongoDB instances.

### 4.6 Development Process and Methodologies

The project was developed following an iterative and incremental methodology.
1.  **Requirement Elicitation & Planning:** Initial requirements were captured in the Software Requirements Specification (SRS.md).
2.  **Foundation First:** Core functionalities like user authentication and basic data models (Users, Courses, Questions) were implemented first in the backend, followed by corresponding frontend interfaces.
3.  **Modular Development:** Features were built module by module (e.g., Survey creation, then Survey taking, then Results display).
4.  **Iterative Refinement:** As core features were completed, they were tested, and feedback (simulated or actual) led to refinements. Examples include the adjustment of the overall survey score calculation and the enhancement of UI elements like the `MyAttemptsPage` to show more survey context.
5.  **Testing Strategy:**
    *   **Backend:** Unit tests for critical logic (e.g., `test_scoring_logic.py`) and integration tests for all API endpoints using Pytest and FastAPI's `TestClient`. Automated database cleanup fixtures were used to ensure test isolation.
    *   **Frontend:** Primarily manual testing of user flows and component interactions.
6.  **Version Control:** Git was used for version control (assumed, standard practice).
7.  **Tooling:** FastAPI, React, TypeScript, Vite, Pydantic, MongoDB, Docker, Nginx, Pytest, Axios, TailwindCSS were key tools and libraries.

### 4.7 Key Design Decisions and Justifications

Several key design decisions were made to meet the project's requirements and adhere to good software engineering practices:

*   **Decoupled Architecture (FastAPI + React SPA):** This separation allows for independent development cycles, technology stack evolution for each tier, and better scalability. The API serves as a clear contract.
*   **Python/FastAPI for Backend:** Python's extensive libraries and FastAPI's performance, ease of use, automatic validation (via Pydantic), and built-in OpenAPI documentation generation made it a strong choice for rapid API development. Asynchronous support is critical for efficient I/O operations with the database.
*   **React/TypeScript for Frontend:** React's component model and virtual DOM offer efficient rendering and UI reusability. TypeScript provides type safety, crucial for reducing bugs and improving maintainability in a growing JavaScript codebase.
*   **MongoDB as Database:** Chosen for its schema flexibility, which is beneficial for storing diverse question types, scoring rules, and feedback structures that might evolve.
*   **Containerization (Docker/Docker Compose):** Ensures consistent environments across development, testing, and production, simplifying setup and deployment, and mitigating "works on my machine" issues.
*   **Pydantic for Data Integrity:** Using Pydantic models for request/response validation in FastAPI enforces data consistency and reduces errors at the API boundary.
*   **Session-Based Authentication:** Provides a standard and secure method for web application authentication without the complexities of managing tokens on the client-side for this particular application scope.
*   **Modular Design:** Both backend (routers) and frontend (components, services, pages) are structured modularly to enhance organization, testability, and maintainability.
*   **Utility-First CSS (TailwindCSS):** Accelerates UI development by providing pre-defined utility classes, allowing for rapid prototyping and custom designs without extensive custom CSS.

### 4.8 Future Work and Potential Enhancements

While the implemented system fulfills the core requirements, several avenues exist for future development and enhancement:

1.  **SRS-Mandated Features:**
    *   **Dynamic Question Flow:** Implementing logic for questions to be presented based on previous answers, creating adaptive assessment paths.
    *   **External Authentication (JAMK Credentials):** Integrating with an OAuth 2.0 or SAML-based Identity Provider.
    *   **Teacher/Admin User Management:** Building UI and API functionalities for designated users to manage other accounts.
2.  **Functional Enhancements:**
    *   **Advanced Reporting & Analytics:** Providing teachers with visual dashboards, aggregated statistics on student performance, question difficulty analysis, and trend identification.
    *   **Survey Versioning:** Allowing modifications to surveys without affecting results from previous versions.
    *   **Question Bank Improvements:** Enhanced tagging, search, and sharing capabilities for questions.
    *   **Bulk Operations:** E.g., bulk import of questions, bulk assignment of questions to courses.
3.  **User Experience (UX) Improvements:**
    *   **UI Pagination:** Implementing client-side or server-driven pagination for all resource tables (`ResourceTable`) to handle large datasets efficiently.
    *   **Rich Text Editors:** For question details, survey descriptions, and feedback text.
    *   **Enhanced Search & Filtering:** More granular filtering options on management pages.
    *   **"Unsaved Changes" Warnings:** Particularly for the `TakeSurveyPage` and complex forms.
4.  **Technical Enhancements:**
    *   **Automated Frontend Testing:** Implementing end-to-end tests using frameworks like Cypress or Playwright.
    *   **Performance Optimization:** Database query optimization, further React component memoization, and advanced code-splitting as the application scales.
    *   **Accessibility (A11y) Audit:** A formal review and implementation of WCAG guidelines.
    *   **Internationalization (i18n):** Support for multiple languages.
5.  **Documentation:**
    *   **Comprehensive User Guides:** For both student and teacher roles.
    *   **Detailed API Documentation Maintenance:** Ensuring OpenAPI documentation remains current with any API changes.

### 4.9 Conclusion

The implementation phase of the Self-Evaluation Tool has resulted in a robust, functional web application meeting the majority of the initially defined requirements. The chosen technology stack and architectural design have provided a solid foundation for core features such as user management, course and question authoring, survey deployment, student assessment, automated scoring, and results presentation. Key challenges in data modeling for diverse question types and complex scoring logic were addressed through Pydantic's validation capabilities and carefully structured backend services. The iterative development process, coupled with targeted bug fixes and UX refinements like improved results display and contextual tooltips, has culminated in a system ready for further extension and potential pilot usage. The outlined future work indicates significant potential for expanding the tool's capabilities and pedagogical value.